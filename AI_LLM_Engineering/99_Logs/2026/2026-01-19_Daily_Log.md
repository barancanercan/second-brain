# Daily Log: 2026-01-19

---

## Today's Focus

> Improve my web scraping skills and turn what I learn into real projects.

---

## What I Learned Today

*New things I learned and key takeaways.*

### XPaths and Selectors
- How to use XPath syntax and `scrapy` selectors to explore HTML documents
- How to count elements, select body and attributes with XPath
- How to select elements by class and links (href)

### CSS Locators, Chaining, and Responses
- CSS Locator syntax
- How to chain XPath and CSS selectors together
- How to use `Response` objects to scrape multiple sites

---

## What Was Challenging

*Problems I faced and how I solved them.*

- [ ] *Not filled yet - don't forget to fill at end of day!*

---

## Projects & Code

*Projects I worked on and code I wrote today.*

### New GitHub Repo
I created a new [GitHub repo](https://github.com/barancanercan/scraping_datacamp/tree/main) called `scraping_datacamp` to practice what I learned.

### Ankara City Council Members Scraper
I wrote a Python script to scrape the Ankara City Council members page (`ankara.bel.tr/meclis/uyeler`).

**Features:**
- Gets HTML content using `requests` library
- Extracts **name**, **party**, and **district** info using `scrapy.Selector`
- Puts the data into a clean `pandas` DataFrame

<details>
<summary>Code Example</summary>

```python
import requests
from scrapy import Selector
import pandas as pd

def get_name_party_district(url: str, headers: dict):
    data = {"name": [], "party": [], "district": []}
    html = requests.get(url, headers=headers).text
    response = Selector(text=html)
    members = response.css("a.council-member")
    for member in members:
        name = member.css("strong::text").get()
        data["name"].append(name)
        party_name = member.css("span.party::text").get()
        data["party"].append(party_name)
        districts = member.css("span:not(.party)::text").getall()
        district = next((d.strip() for d in districts if d.strip()), "Not specified")
        data["district"].append(district)
    return pd.DataFrame(data)

url = "https://www.ankara.bel.tr/meclis/uyeler"
headers = {"User-Agent": "Mozilla/5.0"}

df_members = get_name_party_district(url, headers)
print(df_members)
```

</details>

---

## What I Will Do Tomorrow

*Tasks and goals for tomorrow.*

- [ ] *Not planned yet*

---

## End of Day Reflection

*How I feel about today and personal notes.*

> [!REFLECTION]
> This work helped me turn theory about selectors and response objects into a real project.

### One Thing I'm Grateful For
- *...*

### My Intention for Tomorrow
- *...*

---

## Daily Score

| Category | Score (1-5) |
|----------|-------------|
| Productivity | |
| Learning | |
| Motivation | |

---

#daily-log #2026-01 #web-scraping
